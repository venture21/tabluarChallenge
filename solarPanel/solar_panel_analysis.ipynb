{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 태양광 발전량 예측\n",
    "\n",
    "이 노트북에서 다루는 내용:\n",
    "1. **탐색적 데이터 분석 (EDA)**\n",
    "2. **데이터 시각화**\n",
    "3. **데이터 전처리**\n",
    "4. **특성 공학**\n",
    "5. **분위수 회귀 모델링**\n",
    "6. **제출 파일 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nimport os\nimport warnings\nimport matplotlib.font_manager as fm\n\nwarnings.filterwarnings('ignore')\n\n# 스타일 먼저 설정 (폰트보다 먼저!)\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 12\n\n# Windows 한글 폰트 직접 경로 지정\nfont_path = 'C:/Windows/Fonts/malgun.ttf'\n\n# 폰트 등록 및 설정\nfm.fontManager.addfont(font_path)\nfont_prop = fm.FontProperties(fname=font_path)\nfont_name = font_prop.get_name()\n\n# rc 설정으로 전역 폰트 변경\nplt.rc('font', family=font_name)\nplt.rcParams['axes.unicode_minus'] = False\n\nprint(f'한글 폰트 설정 완료: {font_name}')\nprint('라이브러리 임포트 완료!')"
  },
  {
   "cell_type": "code",
   "source": "# 한글 폰트 테스트\nprint(f'현재 폰트: {plt.rcParams[\"font.family\"]}')\n\nfig, ax = plt.subplots(figsize=(8, 4))\nax.bar(['월요일', '화요일', '수요일', '목요일', '금요일'], [10, 25, 15, 30, 20], color='skyblue', edgecolor='navy')\nax.set_xlabel('요일')\nax.set_ylabel('발전량 (kW)')\nax.set_title('한글 폰트 테스트 - 태양광 발전량')\nplt.tight_layout()\nplt.show()\n\nprint('\\n한글이 보이면 설정 완료!')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 로드\n",
    "train = pd.read_csv('data/train/train.csv')\n",
    "print(f'학습 데이터 크기: {train.shape}')\n",
    "\n",
    "# 테스트 파일 로드\n",
    "test_files = sorted(glob('data/test/*.csv'), key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
    "print(f'테스트 파일 수: {len(test_files)}')\n",
    "\n",
    "# 샘플 제출 파일 로드\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "print(f'샘플 제출 파일 크기: {sample_submission.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 확인\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 제출 파일 확인\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 탐색적 데이터 분석 (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 기본 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 정보\n",
    "print('='*60)\n",
    "print('데이터 정보')\n",
    "print('='*60)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통계 요약\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "print('='*60)\n",
    "print('결측치 현황')\n",
    "print('='*60)\n",
    "missing = train.isnull().sum()\n",
    "missing_pct = (train.isnull().sum() / len(train)) * 100\n",
    "missing_df = pd.DataFrame({'결측치 수': missing, '결측치 비율(%)': missing_pct})\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼별 고유값 수\n",
    "print('='*60)\n",
    "print('고유값 수')\n",
    "print('='*60)\n",
    "for col in train.columns:\n",
    "    print(f'{col}: {train[col].nunique()}개 고유값')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 타겟 변수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 분포\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 히스토그램\n",
    "axes[0].hist(train['TARGET'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('TARGET (발전량)')\n",
    "axes[0].set_ylabel('빈도')\n",
    "axes[0].set_title('TARGET 분포')\n",
    "\n",
    "# 히스토그램 (0 제외)\n",
    "axes[1].hist(train[train['TARGET'] > 0]['TARGET'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('TARGET (발전량)')\n",
    "axes[1].set_ylabel('빈도')\n",
    "axes[1].set_title('TARGET 분포 (0 제외)')\n",
    "\n",
    "# 박스 플롯\n",
    "axes[2].boxplot(train['TARGET'])\n",
    "axes[2].set_ylabel('TARGET')\n",
    "axes[2].set_title('TARGET 박스 플롯')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 0값 비율\n",
    "zero_pct = (train['TARGET'] == 0).sum() / len(train) * 100\n",
    "print(f'\\nTARGET이 0인 비율: {zero_pct:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 시간대별 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간대별 평균 TARGET\n",
    "hourly_avg = train.groupby('Hour')['TARGET'].mean()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# 막대 그래프\n",
    "axes[0].bar(hourly_avg.index, hourly_avg.values, color='skyblue', edgecolor='navy')\n",
    "axes[0].set_xlabel('시간')\n",
    "axes[0].set_ylabel('평균 TARGET')\n",
    "axes[0].set_title('시간대별 평균 발전량')\n",
    "axes[0].set_xticks(range(0, 24))\n",
    "\n",
    "# 시간-분 히트맵\n",
    "pivot = train.pivot_table(values='TARGET', index='Hour', columns='Minute', aggfunc='mean')\n",
    "sns.heatmap(pivot, cmap='YlOrRd', ax=axes[1], annot=True, fmt='.1f')\n",
    "axes[1].set_title('시간/분별 평균 발전량')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일별 패턴 샘플 (처음 7일)\n",
    "sample_days = train[train['Day'] < 7].copy()\n",
    "sample_days['time_idx'] = sample_days['Day'] * 48 + sample_days['Hour'] * 2 + sample_days['Minute'] // 30\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(sample_days['time_idx'], sample_days['TARGET'], linewidth=1)\n",
    "plt.xlabel('시간 인덱스 (30분 간격)')\n",
    "plt.ylabel('발전량 (kW)')\n",
    "plt.title('발전량 패턴 (처음 7일)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 특성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 분포\n",
    "features = ['DHI', 'DNI', 'WS', 'RH', 'T']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    axes[i].hist(train[feat], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_xlabel(feat)\n",
    "    axes[i].set_ylabel('빈도')\n",
    "    axes[i].set_title(f'{feat} 분포')\n",
    "\n",
    "axes[-1].axis('off')  # 마지막 빈 서브플롯 숨기기\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 행렬\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = train[['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.3f',\n",
    "            linewidths=0.5, square=True)\n",
    "plt.title('상관관계 행렬')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET과의 산점도\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    # 오버플로팅 방지를 위한 샘플링\n",
    "    sample = train.sample(min(5000, len(train)), random_state=42)\n",
    "    axes[i].scatter(sample[feat], sample['TARGET'], alpha=0.3, s=10)\n",
    "    axes[i].set_xlabel(feat)\n",
    "    axes[i].set_ylabel('TARGET')\n",
    "    axes[i].set_title(f'{feat} vs TARGET')\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 일사량 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간대별 DHI, DNI 패턴\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# 시간대별 DHI\n",
    "dhi_hourly = train.groupby('Hour')['DHI'].mean()\n",
    "axes[0].bar(dhi_hourly.index, dhi_hourly.values, color='orange', edgecolor='darkorange')\n",
    "axes[0].set_xlabel('시간')\n",
    "axes[0].set_ylabel('평균 DHI')\n",
    "axes[0].set_title('시간대별 평균 DHI (산란일사량)')\n",
    "axes[0].set_xticks(range(0, 24))\n",
    "\n",
    "# 시간대별 DNI\n",
    "dni_hourly = train.groupby('Hour')['DNI'].mean()\n",
    "axes[1].bar(dni_hourly.index, dni_hourly.values, color='red', edgecolor='darkred')\n",
    "axes[1].set_xlabel('시간')\n",
    "axes[1].set_ylabel('평균 DNI')\n",
    "axes[1].set_title('시간대별 평균 DNI (직달일사량)')\n",
    "axes[1].set_xticks(range(0, 24))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHI (전천일사량) 계산\n",
    "# GHI = DHI + DNI * cos(천정각)\n",
    "# 단순화를 위해 DHI + DNI를 근사값으로 사용\n",
    "train['GHI_proxy'] = train['DHI'] + train['DNI'] * 0.5  # 단순화된 근사\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sample = train.sample(min(5000, len(train)), random_state=42)\n",
    "plt.scatter(sample['GHI_proxy'], sample['TARGET'], alpha=0.3, s=10)\n",
    "plt.xlabel('GHI 근사값 (DHI + 0.5*DNI)')\n",
    "plt.ylabel('TARGET')\n",
    "plt.title('GHI 근사값 vs 발전량')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(test_files):\n",
    "    \"\"\"모든 테스트 파일을 로드하여 결합\"\"\"\n",
    "    test_data = []\n",
    "    for file in test_files:\n",
    "        file_id = int(os.path.basename(file).split('.')[0])\n",
    "        df = pd.read_csv(file)\n",
    "        df['file_id'] = file_id\n",
    "        test_data.append(df)\n",
    "    return test_data\n",
    "\n",
    "test_data = load_test_data(test_files)\n",
    "print(f'{len(test_data)}개의 테스트 파일 로드 완료')\n",
    "print(f'샘플 테스트 파일 크기: {test_data[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 구조 확인\n",
    "test_data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터의 Day 확인\n",
    "print('테스트 파일 0의 Day:', test_data[0]['Day'].unique())\n",
    "print('\\nDay 7과 Day 8을 예측해야 함 (일당 48행 = 파일당 96행)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 특성 공학"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, is_train=True):\n",
    "    \"\"\"모델링을 위한 특성 생성\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 시간 특성\n",
    "    df['time_idx'] = df['Hour'] * 2 + df['Minute'] // 30  # 0-47\n",
    "    \n",
    "    # 순환 시간 특성\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "    df['time_sin'] = np.sin(2 * np.pi * df['time_idx'] / 48)\n",
    "    df['time_cos'] = np.cos(2 * np.pi * df['time_idx'] / 48)\n",
    "    \n",
    "    # 주간 시간대 지표 (근사)\n",
    "    df['is_daylight'] = ((df['Hour'] >= 6) & (df['Hour'] <= 18)).astype(int)\n",
    "    \n",
    "    # 일사량 특성\n",
    "    df['GHI_proxy'] = df['DHI'] + df['DNI'] * 0.5\n",
    "    df['solar_ratio'] = df['DHI'] / (df['DNI'] + 1)  # 0으로 나누기 방지\n",
    "    df['total_irradiance'] = df['DHI'] + df['DNI']\n",
    "    \n",
    "    # 기상 상호작용\n",
    "    df['T_RH'] = df['T'] * df['RH']\n",
    "    df['WS_T'] = df['WS'] * df['T']\n",
    "    df['DHI_T'] = df['DHI'] * df['T']\n",
    "    df['DNI_T'] = df['DNI'] * df['T']\n",
    "    \n",
    "    # 온도 효율 계수 (고온 = 낮은 효율)\n",
    "    df['temp_efficiency'] = 1 - 0.005 * (df['T'] - 25).clip(lower=0)\n",
    "    \n",
    "    # 습도 계수\n",
    "    df['humidity_factor'] = (100 - df['RH']) / 100\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 학습 데이터에 특성 공학 적용\n",
    "train_fe = create_features(train, is_train=True)\n",
    "print(f'특성 공학 후 학습 데이터 크기: {train_fe.shape}')\n",
    "train_fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(df, group_col=None, target_col='TARGET', lags=[1, 2, 3]):\n",
    "    \"\"\"이전 시점 기반 지연 특성 생성\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for lag in lags:\n",
    "        if group_col:\n",
    "            df[f'target_lag_{lag}'] = df.groupby(group_col)[target_col].shift(lag)\n",
    "        else:\n",
    "            df[f'target_lag_{lag}'] = df[target_col].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 일별 패턴 롤링 통계 생성\n",
    "def create_daily_stats(df):\n",
    "    \"\"\"일별 집계 통계 생성\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 모든 날의 시간대별 평균 (일반적인 일별 패턴 캡처)\n",
    "    hour_stats = df.groupby(['Hour', 'Minute']).agg({\n",
    "        'TARGET': ['mean', 'std', 'min', 'max'],\n",
    "        'DHI': 'mean',\n",
    "        'DNI': 'mean',\n",
    "        'T': 'mean'\n",
    "    }).reset_index()\n",
    "    hour_stats.columns = ['Hour', 'Minute', 'target_hour_mean', 'target_hour_std', \n",
    "                          'target_hour_min', 'target_hour_max',\n",
    "                          'DHI_hour_mean', 'DNI_hour_mean', 'T_hour_mean']\n",
    "    \n",
    "    df = df.merge(hour_stats, on=['Hour', 'Minute'], how='left')\n",
    "    \n",
    "    return df, hour_stats\n",
    "\n",
    "train_fe, hour_stats = create_daily_stats(train_fe)\n",
    "print(f'일별 통계 추가 후 학습 데이터 크기: {train_fe.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 새 특성 표시\n",
    "new_features = [col for col in train_fe.columns if col not in train.columns]\n",
    "print('생성된 새 특성:')\n",
    "for feat in new_features:\n",
    "    print(f'  - {feat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 분위수 회귀 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 분위수 정의\n",
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 준비\n",
    "feature_cols = ['Hour', 'Minute', 'DHI', 'DNI', 'WS', 'RH', 'T',\n",
    "                'time_idx', 'hour_sin', 'hour_cos', 'time_sin', 'time_cos',\n",
    "                'is_daylight', 'GHI_proxy', 'solar_ratio', 'total_irradiance',\n",
    "                'T_RH', 'WS_T', 'DHI_T', 'DNI_T', 'temp_efficiency', 'humidity_factor',\n",
    "                'target_hour_mean', 'target_hour_std', 'target_hour_min', 'target_hour_max',\n",
    "                'DHI_hour_mean', 'DNI_hour_mean', 'T_hour_mean']\n",
    "\n",
    "X = train_fe[feature_cols]\n",
    "y = train_fe['TARGET']\n",
    "\n",
    "print(f'특성 크기: {X.shape}')\n",
    "print(f'타겟 크기: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 기반 학습/검증 분할\n",
    "# 마지막 20% 일수를 검증용으로 사용\n",
    "n_days = train_fe['Day'].max() + 1\n",
    "val_start_day = int(n_days * 0.8)\n",
    "\n",
    "train_mask = train_fe['Day'] < val_start_day\n",
    "val_mask = train_fe['Day'] >= val_start_day\n",
    "\n",
    "X_train, X_val = X[train_mask], X[val_mask]\n",
    "y_train, y_val = y[train_mask], y[val_mask]\n",
    "\n",
    "print(f'학습 세트: {X_train.shape}')\n",
    "print(f'검증 세트: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinball_loss(y_true, y_pred, quantile):\n",
    "    \"\"\"특정 분위수에 대한 핀볼 손실 계산\"\"\"\n",
    "    errors = y_true - y_pred\n",
    "    return np.mean(np.maximum(quantile * errors, (quantile - 1) * errors))\n",
    "\n",
    "def train_quantile_model(X_train, y_train, X_val, y_val, quantile, params=None):\n",
    "    \"\"\"특정 분위수에 대한 LightGBM 모델 학습\"\"\"\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'objective': 'quantile',\n",
    "            'alpha': quantile,\n",
    "            'n_estimators': 500,\n",
    "            'learning_rate': 0.05,\n",
    "            'max_depth': 8,\n",
    "            'num_leaves': 50,\n",
    "            'min_child_samples': 20,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': -1\n",
    "        }\n",
    "    \n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 분위수에 대해 모델 학습\n",
    "models = {}\n",
    "val_predictions = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    print(f'분위수 {q} 모델 학습 중...')\n",
    "    model = train_quantile_model(X_train, y_train, X_val, y_val, q)\n",
    "    models[q] = model\n",
    "    \n",
    "    # 검증 예측\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = np.clip(y_pred, 0, None)  # 음수 예측값 클리핑\n",
    "    val_predictions[q] = y_pred\n",
    "    \n",
    "    loss = pinball_loss(y_val, y_pred, q)\n",
    "    print(f'  분위수 {q} - 핀볼 손실: {loss:.4f}')\n",
    "\n",
    "print('\\n모든 모델 학습 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 핀볼 손실 계산\n",
    "total_loss = 0\n",
    "for q in quantiles:\n",
    "    total_loss += pinball_loss(y_val, val_predictions[q], q)\n",
    "avg_loss = total_loss / len(quantiles)\n",
    "print(f'평균 핀볼 손실: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙값 모델(q=0.5)의 특성 중요도\n",
    "median_model = models[0.5]\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': median_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance['feature'][:20], importance['importance'][:20])\n",
    "plt.xlabel('중요도')\n",
    "plt.ylabel('특성')\n",
    "plt.title('상위 20개 특성 중요도 (중앙값 모델)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 검증 예측 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 예측 플롯\n",
    "sample_idx = np.arange(0, min(500, len(y_val)))\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(sample_idx, y_val.iloc[sample_idx].values, 'b-', label='실제값', linewidth=2)\n",
    "plt.fill_between(sample_idx, val_predictions[0.1][sample_idx], val_predictions[0.9][sample_idx], \n",
    "                 alpha=0.3, color='orange', label='10-90% 구간')\n",
    "plt.fill_between(sample_idx, val_predictions[0.3][sample_idx], val_predictions[0.7][sample_idx], \n",
    "                 alpha=0.4, color='orange', label='30-70% 구간')\n",
    "plt.plot(sample_idx, val_predictions[0.5][sample_idx], 'r--', label='중앙값 예측', linewidth=1)\n",
    "plt.xlabel('샘플 인덱스')\n",
    "plt.ylabel('발전량')\n",
    "plt.title('분위수 구간을 포함한 검증 예측')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 테스트 예측 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 학습 데이터로 재학습\n",
    "print('전체 학습 데이터로 모델 재학습 중...')\n",
    "\n",
    "final_models = {}\n",
    "for q in quantiles:\n",
    "    print(f'분위수 {q} 모델 학습 중...')\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'quantile',\n",
    "        'alpha': q,\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 50,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(X, y)\n",
    "    final_models[q] = model\n",
    "\n",
    "print('\\n모든 최종 모델 학습 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_future_predictions(test_df, hour_stats, file_id, final_models, quantiles, feature_cols):\n",
    "    \"\"\"\n",
    "    테스트 데이터(Day 0-6)를 기반으로 Day 7, Day 8의 예측을 생성\n",
    "    \n",
    "    Day 7, Day 8에 대한 기상 데이터가 없으므로:\n",
    "    - 시간대별 통계(hour_stats)를 사용\n",
    "    - 마지막 날(Day 6)의 기상 패턴을 참조\n",
    "    \"\"\"\n",
    "    # 마지막 날(Day 6)의 데이터 가져오기\n",
    "    last_day_data = test_df[test_df['Day'] == 6].copy()\n",
    "    \n",
    "    predictions_list = []\n",
    "    \n",
    "    # Day 7과 Day 8에 대해 예측 생성\n",
    "    for pred_day in [7, 8]:\n",
    "        # 각 시간대에 대해 특성 생성 (48개 시간대: 24시간 * 2)\n",
    "        for hour in range(24):\n",
    "            for minute in [0, 30]:\n",
    "                # 마지막 날의 동일 시간대 데이터 참조\n",
    "                ref_data = last_day_data[(last_day_data['Hour'] == hour) & \n",
    "                                         (last_day_data['Minute'] == minute)]\n",
    "                \n",
    "                if len(ref_data) > 0:\n",
    "                    ref_row = ref_data.iloc[0]\n",
    "                    # 마지막 날의 기상 데이터 사용\n",
    "                    DHI = ref_row['DHI']\n",
    "                    DNI = ref_row['DNI']\n",
    "                    WS = ref_row['WS']\n",
    "                    RH = ref_row['RH']\n",
    "                    T = ref_row['T']\n",
    "                else:\n",
    "                    # 참조 데이터가 없으면 hour_stats 사용\n",
    "                    hour_stat = hour_stats[(hour_stats['Hour'] == hour) & \n",
    "                                           (hour_stats['Minute'] == minute)]\n",
    "                    if len(hour_stat) > 0:\n",
    "                        DHI = hour_stat['DHI_hour_mean'].values[0]\n",
    "                        DNI = hour_stat['DNI_hour_mean'].values[0]\n",
    "                        T = hour_stat['T_hour_mean'].values[0]\n",
    "                    else:\n",
    "                        DHI, DNI, T = 0, 0, 10\n",
    "                    WS, RH = 2.0, 50.0\n",
    "                \n",
    "                # 특성 생성\n",
    "                time_idx = hour * 2 + minute // 30\n",
    "                hour_sin = np.sin(2 * np.pi * hour / 24)\n",
    "                hour_cos = np.cos(2 * np.pi * hour / 24)\n",
    "                time_sin = np.sin(2 * np.pi * time_idx / 48)\n",
    "                time_cos = np.cos(2 * np.pi * time_idx / 48)\n",
    "                is_daylight = 1 if 6 <= hour <= 18 else 0\n",
    "                GHI_proxy = DHI + DNI * 0.5\n",
    "                solar_ratio = DHI / (DNI + 1)\n",
    "                total_irradiance = DHI + DNI\n",
    "                T_RH = T * RH\n",
    "                WS_T = WS * T\n",
    "                DHI_T = DHI * T\n",
    "                DNI_T = DNI * T\n",
    "                temp_efficiency = 1 - 0.005 * max(0, T - 25)\n",
    "                humidity_factor = (100 - RH) / 100\n",
    "                \n",
    "                # hour_stats에서 시간대별 통계 가져오기\n",
    "                hour_stat = hour_stats[(hour_stats['Hour'] == hour) & \n",
    "                                       (hour_stats['Minute'] == minute)]\n",
    "                if len(hour_stat) > 0:\n",
    "                    target_hour_mean = hour_stat['target_hour_mean'].values[0]\n",
    "                    target_hour_std = hour_stat['target_hour_std'].values[0]\n",
    "                    target_hour_min = hour_stat['target_hour_min'].values[0]\n",
    "                    target_hour_max = hour_stat['target_hour_max'].values[0]\n",
    "                    DHI_hour_mean = hour_stat['DHI_hour_mean'].values[0]\n",
    "                    DNI_hour_mean = hour_stat['DNI_hour_mean'].values[0]\n",
    "                    T_hour_mean = hour_stat['T_hour_mean'].values[0]\n",
    "                else:\n",
    "                    target_hour_mean, target_hour_std = 0, 0\n",
    "                    target_hour_min, target_hour_max = 0, 0\n",
    "                    DHI_hour_mean, DNI_hour_mean, T_hour_mean = 0, 0, 10\n",
    "                \n",
    "                # 특성 딕셔너리 생성\n",
    "                features = {\n",
    "                    'Hour': hour, 'Minute': minute, 'DHI': DHI, 'DNI': DNI,\n",
    "                    'WS': WS, 'RH': RH, 'T': T, 'time_idx': time_idx,\n",
    "                    'hour_sin': hour_sin, 'hour_cos': hour_cos,\n",
    "                    'time_sin': time_sin, 'time_cos': time_cos,\n",
    "                    'is_daylight': is_daylight, 'GHI_proxy': GHI_proxy,\n",
    "                    'solar_ratio': solar_ratio, 'total_irradiance': total_irradiance,\n",
    "                    'T_RH': T_RH, 'WS_T': WS_T, 'DHI_T': DHI_T, 'DNI_T': DNI_T,\n",
    "                    'temp_efficiency': temp_efficiency, 'humidity_factor': humidity_factor,\n",
    "                    'target_hour_mean': target_hour_mean, 'target_hour_std': target_hour_std,\n",
    "                    'target_hour_min': target_hour_min, 'target_hour_max': target_hour_max,\n",
    "                    'DHI_hour_mean': DHI_hour_mean, 'DNI_hour_mean': DNI_hour_mean,\n",
    "                    'T_hour_mean': T_hour_mean\n",
    "                }\n",
    "                \n",
    "                # 예측용 DataFrame 생성\n",
    "                X_pred = pd.DataFrame([features])[feature_cols]\n",
    "                \n",
    "                # 각 분위수에 대한 예측\n",
    "                pred_row = {'id': f\"{file_id}.csv_Day{pred_day}_{hour}h{minute:02d}m\"}\n",
    "                for q in quantiles:\n",
    "                    pred_val = final_models[q].predict(X_pred)[0]\n",
    "                    pred_row[f'q_{q}'] = max(0, pred_val)  # 음수 방지\n",
    "                \n",
    "                predictions_list.append(pred_row)\n",
    "    \n",
    "    return pd.DataFrame(predictions_list)\n",
    "\n",
    "# 모든 테스트 파일에 대한 예측 생성\n",
    "print('테스트 파일에 대한 예측 생성 중...')\n",
    "all_predictions = []\n",
    "\n",
    "for i, test_df in enumerate(test_data):\n",
    "    file_id = test_df['file_id'].iloc[0]\n",
    "    \n",
    "    # Day 7, Day 8 예측 생성\n",
    "    pred_df = create_future_predictions(\n",
    "        test_df, hour_stats, file_id, final_models, quantiles, feature_cols\n",
    "    )\n",
    "    all_predictions.append(pred_df)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f'{i+1}/{len(test_data)} 파일 처리 완료')\n",
    "\n",
    "print(f'\\n총 처리된 파일 수: {len(all_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 예측 결합\n",
    "submission = pd.concat(all_predictions, ignore_index=True)\n",
    "\n",
    "print(f'제출 파일 크기: {submission.shape}')\n",
    "print(f'예상 크기: {sample_submission.shape}')\n",
    "print(f'\\\\n제출 파일 컬럼: {submission.columns.tolist()}')\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 형식 검증\n",
    "print('제출 파일 컬럼:', submission.columns.tolist())\n",
    "print('샘플 제출 파일 컬럼:', sample_submission.columns.tolist())\n",
    "\n",
    "# ID 일치 확인\n",
    "submission_ids = set(submission['id'])\n",
    "sample_ids = set(sample_submission['id'])\n",
    "\n",
    "missing_ids = sample_ids - submission_ids\n",
    "extra_ids = submission_ids - sample_ids\n",
    "\n",
    "print(f'\\\\n누락된 ID 수: {len(missing_ids)}')\n",
    "print(f'추가된 ID 수: {len(extra_ids)}')\n",
    "\n",
    "if len(missing_ids) > 0:\n",
    "    print(f'\\\\n누락된 ID 예시: {list(missing_ids)[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 제출 파일과 정렬\n",
    "# 컬럼명을 샘플 제출 파일 형식에 맞게 변경\n",
    "submission_renamed = submission.rename(columns={\n",
    "    f'q_{q}': f'q_{q}' for q in quantiles\n",
    "})\n",
    "\n",
    "# sample_submission의 컬럼명 확인 후 맞추기\n",
    "sample_cols = sample_submission.columns.tolist()\n",
    "print(f'샘플 제출 파일 컬럼명: {sample_cols}')\n",
    "\n",
    "# 컬럼명 매핑 (q_0.1 형식으로)\n",
    "col_mapping = {'id': 'id'}\n",
    "for q in quantiles:\n",
    "    col_mapping[f'q_{q}'] = f'q_{q}'\n",
    "\n",
    "# 최종 제출 파일 생성\n",
    "final_submission = sample_submission[['id']].merge(submission, on='id', how='left')\n",
    "\n",
    "# 누락값을 0으로 채우기\n",
    "final_submission = final_submission.fillna(0)\n",
    "\n",
    "print(f'\\\\n최종 제출 파일 크기: {final_submission.shape}')\n",
    "print(f'컬럼: {final_submission.columns.tolist()}')\n",
    "final_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 저장\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "print('제출 파일이 submission.csv로 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 요약 및 개선 방향\n",
    "\n",
    "### 요약\n",
    "- 태양광 발전량 데이터에 대한 EDA 수행\n",
    "- 시간 기반 및 기상 기반 특성 생성\n",
    "- 9개 분위수에 대한 LightGBM 분위수 회귀 모델 학습\n",
    "- 테스트 데이터에 대한 예측 생성\n",
    "\n",
    "### 잠재적 개선 방향\n",
    "1. **특성 공학**\n",
    "   - 이전 날의 지연 특성 추가\n",
    "   - 계절 지표 포함\n",
    "   - 태양 위치 계산 (천정각)\n",
    "   \n",
    "2. **모델 개선**\n",
    "   - 교차 검증을 통한 하이퍼파라미터 튜닝\n",
    "   - XGBoost, CatBoost와의 앙상블\n",
    "   - 시퀀스 모델링을 위한 신경망\n",
    "   \n",
    "3. **검증 전략**\n",
    "   - K-fold 시계열 교차 검증\n",
    "   - 워크 포워드 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('분석 완료!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}